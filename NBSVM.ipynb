{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is implemented with the help of paper on sentiment classification - https://\n",
    "nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some global declarations\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data():\n",
    "    '''\n",
    "    Function to load train and test data along \n",
    "    with handling of missing data\n",
    "    '''\n",
    "    train = pd.read_csv('./data/train.csv')\n",
    "    test = pd.read_csv('./data/test.csv')\n",
    "    sample_submission = pd.read_csv('./data/sample_submission.csv')\n",
    "    \n",
    "    train['none'] = 1 - train[label_cols].max(axis=1)\n",
    "    train['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "    test['comment_text'].fillna(\"unknown\", inplace=True)\n",
    "    \n",
    "    return train, test, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s): \n",
    "    '''\n",
    "    tokenizer for TFIDF\n",
    "    '''\n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorized_features(train, test):\n",
    "    '''\n",
    "    Convert both test and train comments to term-document \n",
    "    matrix using TFIDF technique.\n",
    "    '''\n",
    "    n = train.shape[0]\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize, min_df=3, \n",
    "                          max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "                          smooth_idf=1, sublinear_tf=1)\n",
    "    train_term_doc = vec.fit_transform(train['comment_text'])\n",
    "    test_term_doc = vec.transform(test['comment_text'])\n",
    "    \n",
    "    return train_term_doc, test_term_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr(x, y_i, y):\n",
    "    '''\n",
    "    Probability function for naive-bayes\n",
    "    '''\n",
    "    p = x[y==y_i].sum(0)\n",
    "    return (p + 1) / ((y == y_i).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(x, y):\n",
    "    '''\n",
    "    SVM model is built on top of Naive Bayes features.\n",
    "    Logistic Regression model is used on top of these features\n",
    "    since it is almost identical to SVM.\n",
    "    '''\n",
    "    y = y.values\n",
    "    r = np.log(pr(x, 1, y) / pr(x, 0, y))\n",
    "    model = LogisticRegression(C=4, dual=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return model.fit(x_nb, y), r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train, test, sample_submission = load_and_process_data()\n",
    "    x_train, x_test = get_vectorized_features(train, test)\n",
    "    preds = np.zeros((len(test), len(label_cols)))\n",
    "    \n",
    "    for i, j in enumerate(label_cols):\n",
    "        model, r = get_model(x_train, train[j])\n",
    "        preds[:, i] = model.predict_proba(x_test.multiply(r))[:, 1]\n",
    "        \n",
    "    submid = pd.DataFrame({'id': sample_submission['id']})\n",
    "    submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "    submission.to_csv('submission_NBSVM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
