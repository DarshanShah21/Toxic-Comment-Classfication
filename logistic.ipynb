{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built using simple Logistic Regression. Text data is transformed into feature vectors using TFIDF on both words as well as characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Load data from csv files.\n",
    "    :return train: Pandas dataframe of complete train data\n",
    "    :return test: Pandas dataframe of complete test data\n",
    "    :return train_text: Pandas series of text comments in train data\n",
    "    :return test_text: Pandas series of text comments in test data\n",
    "    :return all_text: train_text and test_text combined together\n",
    "    '''\n",
    "    # Load data\n",
    "    train = pd.read_csv('./data/train.csv').fillna(' ')\n",
    "    test = pd.read_csv('./data/test.csv').fillna(' ')\n",
    "\n",
    "    # Take comment data\n",
    "    train_text = train['comment_text']\n",
    "    test_text = test['comment_text']\n",
    "    \n",
    "    # Combine train and test\n",
    "    all_text = pd.concat([train_text, test_text])\n",
    "    \n",
    "    return train, test, train_text, test_text, all_text\n",
    "print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyyy\n"
     ]
    }
   ],
   "source": [
    "def get_vectorized_features(train_text, test_text, all_text):\n",
    "    '''\n",
    "    This function applied tf-idf technique on both words and characters\n",
    "    in the text comments to feed to Logistic Regression classifier.\n",
    "    :param train_text: Pandas series containing train comments\n",
    "    :param test_text: Pandas series containing test comments\n",
    "    :param all_text: Pnadas series contaning combined train and text comments\n",
    "    :return combined word and character vectorized features for both\n",
    "        train and test text data\n",
    "    '''\n",
    "    \n",
    "    # For words\n",
    "    word_vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode', \n",
    "                                      analyzer='word',token_pattern=r'\\w{1,}',\n",
    "                                      stop_words='english',ngram_range=(1, 1),\n",
    "                                      max_features=10000)\n",
    "    word_vectorizer.fit(all_text)\n",
    "    train_word_features = word_vectorizer.transform(train_text)\n",
    "    test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "    # For characters\n",
    "    char_vectorizer = TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        strip_accents='unicode',\n",
    "        analyzer='char',\n",
    "        stop_words='english',\n",
    "        ngram_range=(2, 6),\n",
    "        max_features=50000\n",
    "    )\n",
    "    char_vectorizer.fit(all_text)\n",
    "    train_char_features = char_vectorizer.transform(train_text)\n",
    "    test_char_features = char_vectorizer.transform(test_text)\n",
    "\n",
    "    # Stack word and character features\n",
    "    train_features = hstack([train_char_features, train_word_features])\n",
    "    test_features = hstack([test_char_features, test_word_features])\n",
    "    \n",
    "    return train_features, test_features\n",
    "print('heyyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyyyaaa\n"
     ]
    }
   ],
   "source": [
    "def run_classifier(train, test, train_features, test_features):\n",
    "    '''\n",
    "    Runs Logistic Regression model for each individual class as one comment\n",
    "    can have multiple class labels.\n",
    "    :param train: Pandas dataframe of complete train data\n",
    "    :param test: Pandas dataframe of complete test data\n",
    "    :param train_features: Vectorized TFIDF features of text comments in\n",
    "        the train data\n",
    "    :param test_features: Vectorized TFIDF features of text comments in\n",
    "        the test data        \n",
    "    '''\n",
    "    \n",
    "    scores = []\n",
    "    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "    \n",
    "    # Create empty dataframe with each class label to store predictions\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    \n",
    "    # Run for every class\n",
    "    for class_name in class_names:\n",
    "        \n",
    "        # Get labels for current class from train data\n",
    "        train_target = train[class_name]\n",
    "        \n",
    "        # Create a classifier\n",
    "        classifier = LogisticRegression(C=0.1, solver='sag')\n",
    "\n",
    "        # Fit the data\n",
    "        classifier.fit(train_features, train_target)\n",
    "        # Predict\n",
    "        submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "    print('Total CV score is {}'.format(np.mean(scores)))\n",
    "\n",
    "    # Save prediction results (probabilities) to a csv file to analyze later\n",
    "    submission.to_csv('submission_logistic.csv', index=False)\n",
    "    \n",
    "print ('heyyyaaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heyyaa\n",
      "heyyaa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CV score is nan\n",
      "heyyaa\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data, train_text, test_text, all_text = load_data()\n",
    "print('heyyaa')\n",
    "\n",
    "# Get vectorized features using TFIDF on words as well as characters\n",
    "train_features, test_features = get_vectorized_features(train_text, test_text, all_text)\n",
    "print('heyyaa')\n",
    "\n",
    "# Run the model\n",
    "run_classifier(train_data, test_data, train_features, test_features)\n",
    "print('heyyaa')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
